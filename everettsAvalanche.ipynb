{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "combine_weather_avalanche_dataframe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/presidentlines/AvalancheVol3/blob/main/everettsAvalanche.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57d9dbf1"
      },
      "source": [
        "# Team AVYULAUNCH\n",
        "#### E R N K L\n",
        "#### v o  a  a e\n",
        "#### e c  t   n e\n",
        "#### r k  h   e\n",
        "#### e f  a\n",
        "#### t o  n\n",
        "#### t r\n",
        "####   d\n",
        "\n",
        "# 11/13/2021\n",
        "### Combine weather and avalanche data!"
      ],
      "id": "57d9dbf1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0697ca1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "id": "f0697ca1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc1a8729",
        "outputId": "a8be460e-f325-44e1-cd16-8b6449361517"
      },
      "source": [
        "pd.set_option('display.max_rows', 20)\n",
        "\n",
        "df_weather = pd.read_csv('weather.csv')\n",
        "df_weather = df_weather[['NAME', 'DATE', 'PRCP', 'SNWD', 'TMAX', 'TMIN']]\n",
        "\n",
        "# Get month dummy variables\n",
        "df_weather['DATE'] = pd.to_datetime(df_weather['DATE'])\n",
        "df_weather['MONTH'] = pd.DatetimeIndex(df_weather['DATE']).month\n",
        "df_weather['MONTH'] = df_weather['MONTH'].astype(str)\n",
        "df_weather = pd.get_dummies(df_weather, columns=['MONTH'], drop_first=True)\n",
        "\n",
        "def assign_region(name):\n",
        "    if name == \"BEN LOMOND PEAK, UT US\": return \"Ogden\"\n",
        "    if name == \"ALTA, UT US\": return \"Salt Lake\"\n",
        "    if name == \"BEN LOMOND TRAIL, UT US\": return \"Ogden\"\n",
        "    if name == \"MONTE CRISTO, UT US\": return \"Logan\"\n",
        "    if name == \"BUES CANYON UTAH, UT US\": return \"Ogden\"\n",
        "    if name == \"RAY S VALLEY UTAH, UT US\": return \"Uintas\"\n",
        "    if name == \"SNOWBIRD, UT US\": return \"Salt Lake\"\n",
        "\n",
        "df_list = []\n",
        "# Create snow difference by NAME\n",
        "by_location = df_weather.groupby('NAME')\n",
        "for name, group in by_location:\n",
        "    group['Region'] = assign_region(name)\n",
        "    group['snow_diff'] = group['SNWD'] - group['SNWD'].shift(1)\n",
        "    group['temp_range'] = group['TMAX'] - group['TMIN']\n",
        "    df_list.append(group)\n",
        "\n",
        "df_weather = pd.concat(df_list)\n",
        "print(len(df_weather))"
      ],
      "id": "cc1a8729",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4345c436"
      },
      "source": [
        "# Clean up avalanche data\n",
        "df_avalanche = pd.read_csv('avalanches, 11-13-2021.csv')\n",
        "df_avalanche = df_avalanche[['Date', 'Region']].dropna()\n",
        "df_avalanche['DATE'] = pd.to_datetime(df_avalanche['Date'])\n",
        "df_avalanche['Ahvyulaunsh'] = 1"
      ],
      "id": "4345c436",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01f79f4c"
      },
      "source": [
        "# Combine avalanche and weather on region and date\n",
        "df_combined = pd.merge(df_weather, df_avalanche,  how='left', on=['Region', 'DATE'])"
      ],
      "id": "01f79f4c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42fa0596"
      },
      "source": [
        "# Create variable of summed up avalanches per day\n",
        "summed = df_combined.groupby(['NAME', 'DATE'])['Ahvyulaunsh'].agg('sum').reset_index()\n",
        "summed['Avalanche'] = summed['Ahvyulaunsh']\n",
        "reassembled = pd.merge(summed, df_combined, how='left', on=['NAME', 'DATE'])\n",
        "reassembled = reassembled.drop_duplicates()\n",
        "\n",
        "# Final clean up\n",
        "reassembled['Avalanche_binary'] = reassembled['Avalanche'] > 0\n",
        "reassembled = pd.get_dummies(reassembled, columns=['Region'], drop_first=True)\n",
        "reassembled = reassembled.drop(['Ahvyulaunsh_x', 'Ahvyulaunsh_y', 'Date', 'NAME'], axis=1)\n",
        "\n",
        "df_final = reassembled.dropna()\n",
        "df_final.to_csv(\"combined_weather_avalanche.csv\")\n",
        "#print(df_final.columns())"
      ],
      "id": "42fa0596",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af9c99cd",
        "outputId": "c8105dc0-9feb-45b5-bdba-d5c0f25092e2"
      },
      "source": [
        "print(df_final)"
      ],
      "id": "af9c99cd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            DATE  Avalanche  ...  Region_Salt Lake  Region_Uintas\n",
            "1     2000-01-02        0.0  ...                 1              0\n",
            "2     2000-01-03        0.0  ...                 1              0\n",
            "3     2000-01-04        0.0  ...                 1              0\n",
            "4     2000-01-05        0.0  ...                 1              0\n",
            "5     2000-01-06        0.0  ...                 1              0\n",
            "...          ...        ...  ...               ...            ...\n",
            "68545 2021-11-03        0.0  ...                 1              0\n",
            "68546 2021-11-04        0.0  ...                 1              0\n",
            "68547 2021-11-05        0.0  ...                 1              0\n",
            "68548 2021-11-06        0.0  ...                 1              0\n",
            "68549 2021-11-07        0.0  ...                 1              0\n",
            "\n",
            "[41007 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHyUZTmuYWKF"
      },
      "source": [
        ""
      ],
      "id": "OHyUZTmuYWKF",
      "execution_count": null,
      "outputs": []
    }
  ]
}