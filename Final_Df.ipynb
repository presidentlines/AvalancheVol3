{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666afbb5",
   "metadata": {
    "id": "666afbb5"
   },
   "source": [
    "# Team AVYULAUNCH\n",
    "\n",
    "# 11/13/2021\n",
    "### Combine weather and avalanche data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0697ca1",
   "metadata": {
    "id": "f0697ca1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1a8729",
   "metadata": {
    "id": "cc1a8729",
    "outputId": "47afce78-cd3c-490d-f14c-d8055a93b8c2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_dataframe():\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "\n",
    "    # Weather from NOAA Database\n",
    "    df_weather = pd.read_csv('weather with provo.csv')\n",
    "\n",
    "    # Just keeping core features\n",
    "    df_weather = df_weather[['NAME', 'DATE', 'PRCP', 'SNWD', 'TMAX', 'TMIN']]\n",
    "\n",
    "    # Get month dummy variables\n",
    "    df_weather['DATE'] = pd.to_datetime(df_weather['DATE'])\n",
    "    df_weather['MONTH'] = pd.DatetimeIndex(df_weather['DATE']).month\n",
    "    df_weather['MONTH'] = df_weather['MONTH'].astype(str)\n",
    "    df_weather = pd.get_dummies(df_weather, columns=['MONTH'])\n",
    "\n",
    "\n",
    "    # Create Region variable so we can merge with Avalanche dataset\n",
    "    def assign_region(name):\n",
    "        if name == \"BEN LOMOND PEAK, UT US\": return \"Ogden\"\n",
    "        if name == \"ALTA, UT US\": return \"Salt Lake\"\n",
    "        if name == \"BEN LOMOND TRAIL, UT US\": return \"Ogden\"\n",
    "        if name == \"MONTE CRISTO, UT US\": return \"Logan\"\n",
    "        if name == \"BUES CANYON UTAH, UT US\": return \"Ogden\"\n",
    "        if name == \"RAY S VALLEY UTAH, UT US\": return \"Uintas\"\n",
    "        if name == \"SNOWBIRD, UT US\": return \"Salt Lake\"\n",
    "        if name == \"PROVO BYU, UT US\": return \"Provo\"\n",
    "\n",
    "    # Create snow difference by Weather station NAME\n",
    "    df_list = []\n",
    "    by_location = df_weather.groupby('NAME')\n",
    "    for name, group in by_location:\n",
    "        group['Region'] = assign_region(name)\n",
    "\n",
    "        # Snow depth of the day before minus the current day\n",
    "        group['snow_diff_day'] = group['SNWD'] - group['SNWD'].shift(1)\n",
    "        # Change in snow over the last week\n",
    "        group['snow_diff_week'] = group['SNWD'] - group['SNWD'].shift(7)\n",
    "\n",
    "        # Binary saying if we got snow from the day before or not\n",
    "        group['got_snow'] = (group['snow_diff_day'] > 0).astype(int) \n",
    "        df_list.append(group)\n",
    "    df_weather = pd.concat(df_list)\n",
    "\n",
    "    # Create indicator for if it was below freezing at any point that day\n",
    "    df_weather['min_below_freezing'] = (df_weather['TMIN'] < 32).astype(int)\n",
    "    # Create indicator for if it was above freezing at any point that day\n",
    "    df_weather['max_above_freezing'] = (df_weather['TMAX'] > 32).astype(int)\n",
    "\n",
    "    # min * max means:\n",
    "    # 1 if min below freezing and max above freezing\n",
    "    # 0 otherwise\n",
    "    # This is potentially significant if we cross the freezing point of water in a day\n",
    "    df_weather['min*max'] = df_weather['min_below_freezing'] * df_weather['max_above_freezing']\n",
    "\n",
    "\n",
    "    \n",
    "    # Clean up avalanche data\n",
    "    df_avalanche = pd.read_csv('final_avalanche.csv')\n",
    "    # Delete rows without date or region\n",
    "    df_avalanche = df_avalanche[['Date', 'Region']].dropna()\n",
    "    # Convert to date time\n",
    "    df_avalanche['DATE'] = pd.to_datetime(df_avalanche['Date'])\n",
    "    df_avalanche['Avalanche'] = 1\n",
    "    \n",
    "    # Combine avalanche and weather on region and date\n",
    "    df_combined = pd.merge(df_weather, df_avalanche,  how='left', on=['Region', 'DATE'])\n",
    "    \n",
    "    # Create variable of summed up avalanches per day by Weather Station NAME\n",
    "    summed = df_combined.groupby(['NAME', 'DATE'])['Avalanche'].agg('sum').reset_index()\n",
    "    summed['avalanche_sum'] = summed['Avalanche']\n",
    "\n",
    "    # Add new column back onto original dataframe\n",
    "    reassembled = pd.merge(summed, df_combined, how='left', on=['NAME', 'DATE'])\n",
    "    reassembled = reassembled.drop_duplicates()\n",
    "\n",
    "    # Create new column: binary indicator if there was an avalanche that day or not\n",
    "    reassembled['avalanche_binary'] = reassembled['avalanche_sum'] > 0\n",
    "\n",
    "    # Final clean up: drop unnecessary columns\n",
    "    df_final = reassembled.drop(['Avalanche_x', 'Avalanche_y', 'Date', 'NAME'], axis=1)\n",
    "\n",
    "    # Create region dummy variables\n",
    "    df_final = pd.get_dummies(df_final, columns=['Region'], drop_first=True)\n",
    "\n",
    "    # Drop rows with nan variables\n",
    "    df_final = df_final.dropna()\n",
    "\n",
    "    df_final = df_final[df_final['DATE'] > '2010-01-01']\n",
    "\n",
    "    df_final.to_csv(\"FINAL_DF.csv\")\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4345c436",
   "metadata": {
    "id": "4345c436",
    "outputId": "c26a58c7-0def-4b20-91f0-1e78fe455f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NAME', 'DATE', 'PRCP', 'SNWD', 'TMAX', 'TMIN', 'MONTH_1', 'MONTH_10',\n",
      "       'MONTH_11', 'MONTH_12', 'MONTH_2', 'MONTH_3', 'MONTH_4', 'MONTH_5',\n",
      "       'MONTH_6', 'MONTH_7', 'MONTH_8', 'MONTH_9', 'Region', 'snow_diff_day',\n",
      "       'snow_diff_week', 'got_snow', 'min_below_freezing',\n",
      "       'max_above_freezing', 'min*max'],\n",
      "      dtype='object')\n",
      "Index(['Date', 'Region', 'DATE', 'Avalanche'], dtype='object')\n",
      "Index(['DATE', 'avalanche_sum', 'PRCP', 'SNWD', 'TMAX', 'TMIN', 'MONTH_1',\n",
      "       'MONTH_10', 'MONTH_11', 'MONTH_12', 'MONTH_2', 'MONTH_3', 'MONTH_4',\n",
      "       'MONTH_5', 'MONTH_6', 'MONTH_7', 'MONTH_8', 'MONTH_9', 'snow_diff_day',\n",
      "       'snow_diff_week', 'got_snow', 'min_below_freezing',\n",
      "       'max_above_freezing', 'min*max', 'avalanche_binary', 'Region_Ogden',\n",
      "       'Region_Provo', 'Region_Salt Lake', 'Region_Uintas'],\n",
      "      dtype='object')\n",
      "            DATE  avalanche_sum  PRCP  SNWD  TMAX  TMIN  MONTH_1  MONTH_10  \\\n",
      "3519  2010-01-03            1.0  0.00  38.0  31.0  11.0        1         0   \n",
      "3520  2010-01-04            0.0  0.00  37.0  35.0  14.0        1         0   \n",
      "3523  2010-01-07            4.0  0.17  42.0  25.0   7.0        1         0   \n",
      "3527  2010-01-08            1.0  0.00  41.0  35.0  10.0        1         0   \n",
      "3533  2010-01-12            0.0  0.00  37.0  42.0  29.0        1         0   \n",
      "...          ...            ...   ...   ...   ...   ...      ...       ...   \n",
      "68660 2021-11-03            0.0  0.00  10.0  44.0  31.0        0         0   \n",
      "68661 2021-11-04            0.0  0.00  10.0  53.0  40.0        0         0   \n",
      "68662 2021-11-05            0.0  0.00   9.0  51.0  39.0        0         0   \n",
      "68663 2021-11-06            0.0  0.00   8.0  48.0  43.0        0         0   \n",
      "68664 2021-11-07            0.0  0.00   8.0  43.0  31.0        0         0   \n",
      "\n",
      "       MONTH_11  MONTH_12  ...  snow_diff_week  got_snow  min_below_freezing  \\\n",
      "3519          0         0  ...            10.0         0                   1   \n",
      "3520          0         0  ...             9.0         0                   1   \n",
      "3523          0         0  ...            -2.0         1                   1   \n",
      "3527          0         0  ...            -2.0         0                   1   \n",
      "3533          0         0  ...             0.0         0                   1   \n",
      "...         ...       ...  ...             ...       ...                 ...   \n",
      "68660         1         0  ...            -5.0         0                   1   \n",
      "68661         1         0  ...            -4.0         0                   0   \n",
      "68662         1         0  ...            -4.0         0                   0   \n",
      "68663         1         0  ...            -4.0         0                   0   \n",
      "68664         1         0  ...            -4.0         0                   1   \n",
      "\n",
      "       max_above_freezing  min*max  avalanche_binary  Region_Ogden  \\\n",
      "3519                    0        0              True             0   \n",
      "3520                    1        1             False             0   \n",
      "3523                    0        0              True             0   \n",
      "3527                    1        1              True             0   \n",
      "3533                    1        1             False             0   \n",
      "...                   ...      ...               ...           ...   \n",
      "68660                   1        1             False             0   \n",
      "68661                   1        0             False             0   \n",
      "68662                   1        0             False             0   \n",
      "68663                   1        0             False             0   \n",
      "68664                   1        1             False             0   \n",
      "\n",
      "       Region_Provo  Region_Salt Lake  Region_Uintas  \n",
      "3519              0                 1              0  \n",
      "3520              0                 1              0  \n",
      "3523              0                 1              0  \n",
      "3527              0                 1              0  \n",
      "3533              0                 1              0  \n",
      "...             ...               ...            ...  \n",
      "68660             0                 1              0  \n",
      "68661             0                 1              0  \n",
      "68662             0                 1              0  \n",
      "68663             0                 1              0  \n",
      "68664             0                 1              0  \n",
      "\n",
      "[24692 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df = get_dataframe()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d49b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CREATE_FINAL_DF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
